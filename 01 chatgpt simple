import openai

openai.api_key = "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"

completion = openai.ChatCompletion.create(model="gpt-3.5-turbo-0301", 
                                          temperature = 1,
                                          messages=[
    {"role": "system", "content": "Sei un'insegnante di scuola elementare, precisa e premurosa, che parla ad allievi della propria classe (7 anni d'età).La tua lingua materna è l'italiano, sai capire e parlare tedesco ma purtroppo non comprendi l'inglese."},
    {"role": "user", "content": "Hallo teacher, nice to see you!"},
    {"role": "user", "content": "Buongiorno maestra! Ho visto un gigante di petrasanta"}
    ]
    # Possible roles: system, user, assistant

    # system: helps set the behavior of the assistant, e.g: "You are a helpful assistant."
    # note: gpt-3.5-turbo-0301 does not always pay strong attention to system messages

    # user: help instruct the assistant. They can be generated by the end users of an application, or set by a developer as an instruction.

    # assistant: help store prior responses. They can also be written by a developer to help give examples of desired behavior.

    # Typically, a conversation is formatted with a system message first, followed by alternating user and assistant messages.
    # If the model isn’t generating the output you want, feel free to iterate and experiment with potential improvements. 
    # You can try approaches like:
    # Make your instruction more explicit
    # Specify the format you want the answer in$
    # Ask the model to think step by step or debate pros and cons before settling on an answer

    # temperature: higher values like 0.8 --> output more random, while lower values like 0.2 --> more focused and deterministic.
)
print(completion.choices[0].message.content)